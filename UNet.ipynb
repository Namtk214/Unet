{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOaySU/+Q41RVY2Zjf1OlGO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Namtk214/Unet/blob/main/UNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wClsxwPf6api"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models, utils\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FirstFeature(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(FirstFeature, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels) -> None:\n",
        "        super(Encoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            ConvBlock(in_channels, out_channels),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.encoder(x)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.UpsamplingBilinear2d(scale_factor=2),\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.LeakyReLU(),\n",
        "        )\n",
        "    def forward(self, x, skip):\n",
        "        x = self.conv(x)\n",
        "        x = torch.cat((x, skip), dim=1)\n",
        "        x = self.conv_block(x)\n",
        "        return x\n",
        "\n",
        "class FinalOutput(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(FinalOutput, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)"
      ],
      "metadata": {
        "id": "78FWa1tD77pt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Unet(nn.Module):\n",
        "    def __init__(self, n_channel=3, n_classes=3, features=[64, 128, 256, 512, 1024]):\n",
        "        super(Unet, self).__init__()\n",
        "        self.n_channel = n_channel\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "        self.in_conv1 = FirstFeature(n_channel, features[0])\n",
        "        self.in_conv2 = ConvBlock(features[0], features[0])\n",
        "\n",
        "        self.enc1 = Encoder(features[0], features[1])\n",
        "        self.enc2 = Encoder(features[1], features[2])\n",
        "        self.enc3 = Encoder(features[2], features[3])\n",
        "        self.enc4 = Encoder(features[3], features[4])\n",
        "\n",
        "        self.dec1 = Decoder(features[4], features[3])\n",
        "        self.dec2 = Decoder(features[3], features[2])\n",
        "        self.dec3 = Decoder(features[2], features[1])\n",
        "        self.dec4 = Decoder(features[1], features[0])\n",
        "\n",
        "        self.out_conv = FinalOutput(features[0], n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.in_conv1(x)\n",
        "        x1 = self.in_conv2(x)\n",
        "        x2 = self.enc1(x1)\n",
        "        x3 = self.enc2(x2)\n",
        "        x4 = self.enc3(x3)\n",
        "        x5 = self.enc4(x4)\n",
        "        x = self.dec1(x5, x4)\n",
        "        x = self.dec2(x, x3)\n",
        "        x = self.dec3(x, x2)\n",
        "        x = self.dec4(x, x1)\n",
        "        x = self.out_conv(x)\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "O7ct-cMf-sa9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Super Resolution"
      ],
      "metadata": {
        "id": "qk_HZ_t9BhgO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "self.resize_fnc = transforms.Resize(LOW_IMG_HEIGHT*4, LOW_IMG_HEIGHT*4, antialias=True)\n",
        "x = self.resize_fnc(x)"
      ],
      "metadata": {
        "id": "vdZ9x_9kBkU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FirstFeatureNoSkip(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(FirstFeatureNoSkip, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class ConvBlockNoSkip(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(ConvBlockNoSkip, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class EncoderNoSkip(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels) -> None:\n",
        "        super(EncoderNoSkip, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            ConvBlockNoSkip(in_channels, out_channels),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.encoder(x)\n",
        "\n",
        "class DecoderNoSkip(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(DecoderNoSkip, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.UpsamplingBilinear2d(scale_factor=2),\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.LeakyReLU(),\n",
        "        )\n",
        "        self.conv_block = ConvBlockNoSkip(in_channels, out_channels)\n",
        "    def forward(self, x, skip):\n",
        "        x = self.conv(x)\n",
        "        x = torch.cat((x, skip), dim=1)\n",
        "        x = self.conv_block(x)\n",
        "        return x\n",
        "\n",
        "class FinalOutputNoSkip(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(FinalOutputNoSkip, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class SR_Unet_NoSkip(nn.Module):\n",
        "    def __init__(self, n_channel=3, n_classes=3, features=[64, 128, 256, 512, 1024]):\n",
        "        super(SR_Unet_NoSkip, self).__init__()\n",
        "        self.n_channel = n_channel\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "        self.in_conv1 = FirstFeatureNoSkip(n_channel, features[0])\n",
        "        self.in_conv2 = ConvBlockNoSkip(features[0], features[0])\n",
        "\n",
        "        self.enc1 = EncoderNoSkip(features[0], features[1])\n",
        "        self.enc2 = EncoderNoSkip(features[1], features[2])\n",
        "        self.enc3 = EncoderNoSkip(features[2], features[3])\n",
        "        self.enc4 = EncoderNoSkip(features[3], features[4])\n",
        "\n",
        "        self.dec1 = DecoderNoSkip(features[4], features[3])\n",
        "        self.dec2 = DecoderNoSkip(features[3], features[2])\n",
        "        self.dec3 = DecoderNoSkip(features[2], features[1])\n",
        "        self.dec4 = DecoderNoSkip(features[1], features[0])\n",
        "\n",
        "        self.out_conv = FinalOutputNoSkip(features[0], n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.resize_fnc(x)\n",
        "        x = self.in_conv1(x)\n",
        "        x = self.in_conv2(x)\n",
        "\n",
        "        x = self.enc1(x)\n",
        "        x = self.enc2(x)\n",
        "        x = self.enc3(x)\n",
        "        x = self.enc4(x)\n",
        "\n",
        "        x = self.dec1(x)\n",
        "        x = self.dec2(x)\n",
        "        x = self.dec3(x)\n",
        "        x = self.dec4(x)\n",
        "\n",
        "        x = self.out_conv(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "XzPJroE_WV8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, img_dir, is_train=True):\n",
        "        self.img_dir = img_dir\n",
        "        self.is_train = is_train\n",
        "        self.img_list = os.listdir(img_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_list)\n",
        "\n",
        "    def normalize(self, x):\n",
        "        return (x - x.min()) / (x.max() - x.min())\n",
        "\n",
        "    def random_jitter(self, input_image, target_image):\n",
        "        if torch.rand([]) < 0.5:\n",
        "            input_image = transforms.functional.hflip(input_image)\n",
        "            target_image = transforms.functional.hflip(target_image)\n",
        "\n",
        "        return input_image, target_image\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_list[idx])\n",
        "        image = np.array(Image.open(img_path)).convert('RGB')\n",
        "        image = transforms.ToTensor()(image)\n",
        "        input_image = self.resize(image).type(torch.float32)\n",
        "        target_image = self.resize(image).type(torch.float32)\n",
        "        input_image, target_image = self.normalize(input_image), self.normalize(target_image)\n",
        "        if self.is_train:\n",
        "            input_image, target_image = self.random_jitter(input_image, target_image)\n",
        "\n",
        "        return input_image, target_image"
      ],
      "metadata": {
        "id": "Z6f_DVo9Y85y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}